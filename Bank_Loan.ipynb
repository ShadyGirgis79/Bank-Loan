{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShadyGirgis79/Bank-Loan/blob/main/Bank_Loan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS6fg3XboWP3"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UBdkvi4gr5sa"
      },
      "outputs": [],
      "source": [
        "# Essentials\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Models\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "# Postprocessing\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSudxcSHaE78"
      },
      "source": [
        "# Dataset: **\"Bank Loan\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "EAI2GkCzaBEt",
        "outputId": "220337b4-f6ba-47ac-ccdc-e9b4d3090f88"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'loan_train.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-976789e16347>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loan_train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'loan_train.csv'"
          ]
        }
      ],
      "source": [
        "bank = pd.read_csv(\"loan_train.csv\")\n",
        "print(bank.shape)\n",
        "bank.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvJBdn-vaBAu"
      },
      "outputs": [],
      "source": [
        "bank.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgEiDM-rjGum"
      },
      "outputs": [],
      "source": [
        "bank.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulUSyAk_jGrN"
      },
      "outputs": [],
      "source": [
        "bank.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_flSC66t9Fo"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWDmAUoZa0wF"
      },
      "source": [
        "## Changing Categorical Values to Numerical Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKQp9ZKvaA-G"
      },
      "outputs": [],
      "source": [
        "# There are 3 categorical columns: 'Gender', 'education', and 'loan_status'\n",
        "bank['Gender'] = bank['Gender'].map({'male':1 ,'female':0})\n",
        "bank['education'] = bank['education'].map({'High School or Below':0 ,'college':1, 'Bechalor':2, 'Master or Above':3})\n",
        "bank['loan_status'] = bank['loan_status'].map({'PAIDOFF':0 ,'COLLECTION':1})\n",
        "bank.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36vIblXqvJ1E"
      },
      "source": [
        "## Managing Date Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faqWd_HEaAy-"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "eff_dates = []\n",
        "for days in bank['effective_date']:\n",
        "  dates = datetime.strptime(days, \"%m/%d/%Y\")\n",
        "  ordinal_day = dates.timetuple().tm_yday\n",
        "  eff_dates.append(ordinal_day)\n",
        "\n",
        "bank['effective_date'] = eff_dates\n",
        "bank.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KubgbRAYeHZ8"
      },
      "outputs": [],
      "source": [
        "due_dates = []\n",
        "for days in bank['due_date']:\n",
        "  dates = datetime.strptime(days, \"%m/%d/%Y\")\n",
        "  ordinal_day = dates.timetuple().tm_yday\n",
        "  due_dates.append(ordinal_day)\n",
        "\n",
        "bank['due_date'] = due_dates\n",
        "bank.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBtszxaqlry7"
      },
      "source": [
        "## Data Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33a8HqNyjGmV"
      },
      "outputs": [],
      "source": [
        "big_values_columns = ['Principal', 'terms' , 'effective_date' , 'due_date' , 'age']\n",
        "\n",
        "# Initialize the MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit and transform the selected columns using Min-Max normalization\n",
        "bank[big_values_columns] = scaler.fit_transform(bank[big_values_columns])\n",
        "\n",
        "bank.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KWWhD0xgYYh"
      },
      "source": [
        "## Removing Unneeded Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYD5vmjWgiRP"
      },
      "outputs": [],
      "source": [
        "bank = bank.drop(['Unnamed: 0.1','Unnamed: 0'] , axis = 1)\n",
        "bank.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o1GK5d0nDgv"
      },
      "source": [
        "## Removing Outliers using the Z-Score Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bx_AJG6YnApu"
      },
      "outputs": [],
      "source": [
        "#Calculate the mean and standard deviation for each column\n",
        "bank_means = np.mean(bank, axis=0)\n",
        "phone_std_devs = np.std(bank, axis=0)\n",
        "\n",
        "#Calculate the z-score for each cell based on its column\n",
        "z_scores_bank = (bank - bank_means) / phone_std_devs\n",
        "\n",
        "#Define a threshold for outliers (e.g., ±3 standard deviations)\n",
        "threshold = 3\n",
        "\n",
        "#Identify outliers\n",
        "outliers_BCD = np.abs(z_scores_bank) > threshold\n",
        "\n",
        "print(z_scores_bank.shape)\n",
        "z_scores_bank.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgmOut95nAhP"
      },
      "outputs": [],
      "source": [
        "#Remove outliers\n",
        "bank_cleaned = bank[~np.any(outliers_BCD, axis=1)]\n",
        "\n",
        "print(bank_cleaned.shape)\n",
        "bank_cleaned.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZcPvr_Dn4CH"
      },
      "source": [
        "## Correlation Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sjvpyAan1pl"
      },
      "outputs": [],
      "source": [
        "#Exclude output column\n",
        "feature_columns = bank_cleaned.iloc[:, 1:]\n",
        "\n",
        "#Calculate the correlation matrix\n",
        "corr_matrix = feature_columns.corr()\n",
        "\n",
        "#Create a heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title('Correlation Heatmap of Features')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YE6nn46Cn1j1"
      },
      "outputs": [],
      "source": [
        "bank = pd.DataFrame(bank_cleaned)\n",
        "print(bank.shape)\n",
        "bank.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql1XqeRmoTXR"
      },
      "source": [
        "## Splitting the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGANTpPHn1gk"
      },
      "outputs": [],
      "source": [
        "X = bank.drop(['loan_status'] , axis = 1)\n",
        "y = bank['loan_status']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf5StlQYq4fa"
      },
      "source": [
        "## Dictionaries for Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0IpR-0Vq8sa"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary of accuracies for later comparison between models\n",
        "accuracies = {}\n",
        "\n",
        "# Create a dictionary of times for later comparison between models\n",
        "times = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pX6a7Gj5pZa"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy10ZJYlE2dF"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r37XtHiREWBE"
      },
      "outputs": [],
      "source": [
        "# Training the model 15 times; each with different k, ranging from 1 to 15\n",
        "k_values = range(1, 16)\n",
        "errors = []\n",
        "for k in k_values:\n",
        "  knn = KNeighborsClassifier(n_neighbors=k)\n",
        "  knn.fit(X_train, y_train)\n",
        "  knn_pred = knn.predict(X_test)\n",
        "  error = 1 - accuracy_score(y_test, knn_pred)\n",
        "  errors.append(error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LUNAuaJE8ts"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({'Test values':y_test, 'Predict': knn_pred}).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "My-wEpxJfmRT"
      },
      "outputs": [],
      "source": [
        "# Plot the elbow curve\n",
        "plt.plot(k_values, errors)\n",
        "plt.xlabel('Number of Neighbors (k)')\n",
        "plt.ylabel('Error Rate')\n",
        "plt.title('Elbow Curve for KNN')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPAdbliyg-w0"
      },
      "outputs": [],
      "source": [
        "# The best k is 9, as it has the lowest error rate, which is wider than where k = 4, so is more stable\n",
        "knn = KNeighborsClassifier(n_neighbors=15)\n",
        "start_time = time.time()\n",
        "knn.fit(X_train, y_train)\n",
        "tt_knn = time.time() - start_time\n",
        "times['knn'] = tt_knn\n",
        "knn_pred = knn.predict(X_test)\n",
        "knn_acc = accuracy_score(y_test, knn_pred)\n",
        "accuracies['knn'] = knn_acc\n",
        "print(\"Accuracy:\", knn_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5hvhBRIT2mU"
      },
      "outputs": [],
      "source": [
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(y_test, knn_pred)\n",
        "\n",
        "# Create a confusion matrix heatmap\n",
        "sns.heatmap(cm, annot=True, cmap='Blues')\n",
        "\n",
        "# Add labels for axes\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQYCnlPzF1Gs"
      },
      "source": [
        "## Naïve Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "geCOHMtKFONs"
      },
      "outputs": [],
      "source": [
        "# This model has only one parameter which is 'var_smoothing', and its best value is the default: '1e-9'\n",
        "nb = GaussianNB()\n",
        "start_time = time.time()\n",
        "nb.fit(X_train, y_train)\n",
        "tt_nb = time.time() - start_time\n",
        "times['nb'] = tt_nb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sD9PYJcRGHO-"
      },
      "outputs": [],
      "source": [
        "nb_pred = nb.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOA1VQ9QGUT8"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({'Test values':y_test, 'Predict': nb_pred}).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zw0OSLtXGMr9"
      },
      "outputs": [],
      "source": [
        "nb_acc = accuracy_score(y_test, nb_pred)\n",
        "accuracies['nb'] = nb_acc\n",
        "print(\"Accuracy:\", nb_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sNQTQJUXfbc"
      },
      "outputs": [],
      "source": [
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(y_test, nb_pred)\n",
        "\n",
        "# Create a confusion matrix heatmap\n",
        "sns.heatmap(cm, annot=True, cmap='Blues')\n",
        "\n",
        "# Add labels for axes\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj6LKeaCHH4s"
      },
      "source": [
        "## MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "th4v0Ol6HfYo"
      },
      "outputs": [],
      "source": [
        "# Training with default parameters: a 100-node hidden layer, relu activation, adam solver, and alpha=0.0001\n",
        "mlp = MLPClassifier(random_state=42)\n",
        "start_time = time.time()\n",
        "mlp.fit(X_train, y_train)\n",
        "tt_mlp_1 = time.time() - start_time\n",
        "times['mlp_1'] = tt_mlp_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLVJli-3HfVF"
      },
      "outputs": [],
      "source": [
        "mlp_pred = mlp.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_HK5GhzIBtW"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({'Test values':y_test, 'Predict': mlp_pred}).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RW4he7fKH1sR"
      },
      "outputs": [],
      "source": [
        "mlp_acc = accuracy_score(y_test, mlp_pred)\n",
        "accuracies['mlp_1'] = mlp_acc\n",
        "print(\"Accuracy:\", mlp_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsTeEzWGRFIf"
      },
      "outputs": [],
      "source": [
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(y_test, mlp_pred)\n",
        "\n",
        "# Create a confusion matrix heatmap\n",
        "sns.heatmap(cm, annot=True, cmap='Blues')\n",
        "\n",
        "# Add labels for axes\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix 1')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oBHi2h-OvLy"
      },
      "source": [
        "### Changing the Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA5icO0kOv4z"
      },
      "outputs": [],
      "source": [
        "# Changing parameters: 3 hidden layers with 160, 80, 40 nodes, tanh activation, and lbfgs solver\n",
        "mlp_2 = MLPClassifier(hidden_layer_sizes=(160, 80, 40), activation='tanh', solver='lbfgs', random_state=42)\n",
        "start_time = time.time()\n",
        "mlp_2.fit(X_train, y_train)\n",
        "tt_mlp_2 = time.time() - start_time\n",
        "times['mlp_2'] = tt_mlp_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qymSBCurOwSt"
      },
      "outputs": [],
      "source": [
        "mlp_pred_2 = mlp_2.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhcsweE4SjVF"
      },
      "outputs": [],
      "source": [
        "mlp_acc_2 = accuracy_score(y_test, mlp_pred_2)\n",
        "accuracies['mlp_2'] = mlp_acc_2\n",
        "print(\"Accuracy:\", mlp_acc_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFYZPup2VA7B"
      },
      "outputs": [],
      "source": [
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(y_test, mlp_pred_2)\n",
        "\n",
        "# Create a confusion matrix heatmap\n",
        "sns.heatmap(cm, annot=True, cmap='Blues')\n",
        "\n",
        "# Add labels for axes\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix 2')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yesXApZIGmp"
      },
      "source": [
        "### Changing the Hyperparameters Once More"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B9gL80aIJ2c"
      },
      "outputs": [],
      "source": [
        "# Increasing the max number of iterations from 200 to 1000\n",
        "mlp_3 = MLPClassifier(hidden_layer_sizes=(160, 80, 40), activation='tanh', solver='lbfgs', max_iter=1000, random_state=42)\n",
        "start_time = time.time()\n",
        "mlp_3.fit(X_train, y_train)\n",
        "tt_mlp_3 = time.time() - start_time\n",
        "times['mlp_3'] = tt_mlp_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWL-TgA9IWR4"
      },
      "outputs": [],
      "source": [
        "mlp_pred_3 = mlp_3.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "___9UyGwIafb"
      },
      "outputs": [],
      "source": [
        "mlp_acc_3 = accuracy_score(y_test, mlp_pred_3)\n",
        "accuracies['mlp_3'] = mlp_acc_3\n",
        "print(\"Accuracy:\", mlp_acc_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5U__aslvjBn"
      },
      "outputs": [],
      "source": [
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(y_test, mlp_pred_3)\n",
        "\n",
        "# Create a confusion matrix heatmap\n",
        "sns.heatmap(cm, annot=True, cmap='Blues')\n",
        "\n",
        "# Add labels for axes\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix 3')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCKn0u4RH_hH"
      },
      "source": [
        "**The model with the 3 hidden layers and 1000 iterations is the best of 3.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MeEfLA0Iu6s"
      },
      "source": [
        "## SVM classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZmPUq8SI96R"
      },
      "outputs": [],
      "source": [
        "# Training with the default kernel 'rbf'\n",
        "svm = SVC(random_state=42)\n",
        "start_time = time.time()\n",
        "svm.fit(X_train, y_train)\n",
        "tt_svm_1 = time.time() - start_time\n",
        "times['svm_1'] = tt_svm_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wGMo3eGI938"
      },
      "outputs": [],
      "source": [
        "svm_pred = svm.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5u04LZ5RI9ys"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({'Test values':y_test, 'Predict': svm_pred}).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qyxx2VlCJNYj"
      },
      "outputs": [],
      "source": [
        "svm_acc = accuracy_score(y_test, svm_pred)\n",
        "accuracies['svm_1'] = svm_acc\n",
        "print(\"Accuracy:\", svm_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYVBKtcijyGS"
      },
      "outputs": [],
      "source": [
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(y_test, svm_pred)\n",
        "\n",
        "# Create a confusion matrix heatmap\n",
        "sns.heatmap(cm, annot=True, cmap='Blues')\n",
        "\n",
        "# Add labels for axes\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix 1')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "730VU6A7Os8R"
      },
      "source": [
        "### Changing the Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcTVqXz5Ott6"
      },
      "outputs": [],
      "source": [
        "# Training with a polynomial 2nd degree kernel\n",
        "svm_2 = SVC(kernel='poly', degree=2, random_state=42)\n",
        "start_time = time.time()\n",
        "svm_2.fit(X_train, y_train)\n",
        "tt_svm_2 = time.time() - start_time\n",
        "times['svm_2'] = tt_svm_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jp2qAzpoOuQP"
      },
      "outputs": [],
      "source": [
        "svm_pred_2 = svm_2.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yheNaxzRlp-"
      },
      "outputs": [],
      "source": [
        "svm_acc_2 = accuracy_score(y_test, svm_pred_2)\n",
        "accuracies['svm_2'] = svm_acc_2\n",
        "print(\"Accuracy:\", svm_acc_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBoXO6zyj3xq"
      },
      "outputs": [],
      "source": [
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(y_test, svm_pred_2)\n",
        "\n",
        "# Create a confusion matrix heatmap\n",
        "sns.heatmap(cm, annot=True, cmap='Blues')\n",
        "\n",
        "# Add labels for axes\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix 2')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrMf4IzwHrqY"
      },
      "source": [
        "**Changing the parameters did not change anything!**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCYFVDeTJviL"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xufTSwsQKA-U"
      },
      "outputs": [],
      "source": [
        "# Training with a tree of max depth 3\n",
        "dt = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "start_time = time.time()\n",
        "dt.fit(X_train, y_train)\n",
        "tt_dt_1 = time.time() - start_time\n",
        "times['dt_1'] = tt_dt_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84KEDeHNA0AZ"
      },
      "outputs": [],
      "source": [
        "# Get feature importances\n",
        "feature_importances = dt.feature_importances_\n",
        "\n",
        "# Get feature names\n",
        "feature_names = feature_names = bank.columns.tolist()\n",
        "\n",
        "# Sort feature importances and feature names by importance (optional for better readability)\n",
        "feature_importances_sorted = feature_importances.argsort()  # Sort indices by importance\n",
        "feature_names_sorted = [feature_names[i] for i in feature_importances_sorted]  # Sort names by importance (if applicable)\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size as desired\n",
        "plt.barh(feature_names_sorted, feature_importances[feature_importances_sorted], color='skyblue')  # Use sorted importance and names (if applicable)\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Feature Name')\n",
        "plt.title('Feature Importance for Decision Tree Classifier')\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
        "plt.gca().invert_yaxis()  # Invert y-axis to display most important feature at the top\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JThn_v5iKBEa"
      },
      "outputs": [],
      "source": [
        "# Convert feature names to strings\n",
        "feature_names_str = [str(feature) for feature in X.columns]\n",
        "\n",
        "# Convert class names to strings\n",
        "class_names_str = [str(class_) for class_ in dt.classes_]\n",
        "\n",
        "# Plot the decision tree with string names\n",
        "plt.figure(figsize=(18, 9))\n",
        "tree.plot_tree(dt, feature_names=feature_names_str, class_names=class_names_str, filled=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuXTNhABKBBY"
      },
      "outputs": [],
      "source": [
        "dt_pred = dt.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEL5p__MMCce"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({'Test values':y_test, 'Predict': dt_pred}).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFMa1KP7MFFO"
      },
      "outputs": [],
      "source": [
        "dt_acc = accuracy_score(y_test, dt_pred)\n",
        "accuracies['dt_1'] = dt_acc\n",
        "print(\"Accuracy:\", dt_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjb-JogynHj6"
      },
      "outputs": [],
      "source": [
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(y_test, dt_pred)\n",
        "\n",
        "# Create a confusion matrix heatmap\n",
        "sns.heatmap(cm, annot=True, cmap='Blues')\n",
        "\n",
        "# Add labels for axes\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix 1')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz-OT0glNlth"
      },
      "source": [
        "### Changing the Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYQolOv3NQcu"
      },
      "outputs": [],
      "source": [
        "# Allowing the tree to go deep as it needs\n",
        "dt_2 = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
        "start_time = time.time()\n",
        "dt_2.fit(X_train, y_train)\n",
        "tt_dt_2 = time.time() - start_time\n",
        "times['dt_2'] = tt_dt_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCZJoPwdBnoQ"
      },
      "outputs": [],
      "source": [
        "# Get feature importances\n",
        "feature_importances = dt_2.feature_importances_\n",
        "\n",
        "# Get feature names\n",
        "feature_names = feature_names = bank.columns.tolist()\n",
        "\n",
        "# Sort feature importances and feature names by importance (optional for better readability)\n",
        "feature_importances_sorted = feature_importances.argsort()  # Sort indices by importance\n",
        "feature_names_sorted = [feature_names[i] for i in feature_importances_sorted]  # Sort names by importance (if applicable)\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size as desired\n",
        "plt.barh(feature_names_sorted, feature_importances[feature_importances_sorted], color='skyblue')  # Use sorted importance and names (if applicable)\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Feature Name')\n",
        "plt.title('Feature Importance for Decision Tree Classifier')\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
        "plt.gca().invert_yaxis()  # Invert y-axis to display most important feature at the top\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gXYzaJHuQ1w"
      },
      "outputs": [],
      "source": [
        "# Convert feature names to strings\n",
        "feature_names_str = [str(feature) for feature in X.columns]\n",
        "\n",
        "# Convert class names to strings\n",
        "class_names_str = [str(class_) for class_ in dt_2.classes_]\n",
        "\n",
        "# Plot the decision tree with string names\n",
        "plt.figure(figsize=(18, 9))\n",
        "tree.plot_tree(dt_2, feature_names=feature_names_str, class_names=class_names_str, filled=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjAq26EpNhKc"
      },
      "outputs": [],
      "source": [
        "dt_pred_2 = dt_2.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_1r9sEiOg3a"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({'Test values':y_test, 'Predict': dt_pred_2}).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuIcWEuqNhEc"
      },
      "outputs": [],
      "source": [
        "dt_acc_2 = accuracy_score(y_test, dt_pred_2)\n",
        "accuracies['dt_2'] = dt_acc_2\n",
        "print(\"Accuracy:\", dt_acc_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6Sr5uDFpmkO"
      },
      "outputs": [],
      "source": [
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(y_test, dt_pred_2)\n",
        "\n",
        "# Create a confusion matrix heatmap\n",
        "sns.heatmap(cm, annot=True, cmap='Blues')\n",
        "\n",
        "# Add labels for axes\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix 2')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA1x46FyIn4W"
      },
      "source": [
        "**Simpler tree is better!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhbM0XJjQoEH"
      },
      "source": [
        "# Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxs14IRaWIa4"
      },
      "source": [
        "## Training Time Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kL4IbB-uVdS_"
      },
      "outputs": [],
      "source": [
        "# Extract model names and times for plotting\n",
        "models = list(times.keys())\n",
        "times = list(times.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nx7YROFQViZq"
      },
      "outputs": [],
      "source": [
        "# Get the minimum time\n",
        "min_time = min(times)\n",
        "\n",
        "# Get the maximum time\n",
        "max_time = max(times)\n",
        "\n",
        "# Define a color for the maximum time bar\n",
        "max_time_color = 'lightgreen'\n",
        "\n",
        "# Create a list to hold bar colors (default blue for all except max time)\n",
        "bar_colors = ['skyblue'] * len(models)\n",
        "\n",
        "# Find the index of the model with the maximum time\n",
        "max_index = times.index(max_time)\n",
        "\n",
        "# Set the color of the maximum time bar\n",
        "bar_colors[max_index] = max_time_color\n",
        "\n",
        "# Create a bar chart\n",
        "plt.figure(figsize=(8, 6))  # Adjust figure size as desired\n",
        "plt.bar(models, times, color=bar_colors)\n",
        "plt.xlabel('Machine Learning Model')\n",
        "plt.ylabel('Training Time (Seconds)')\n",
        "plt.title('Comparison of Model Training Times')\n",
        "plt.ylim(min_time - 0.01, max_time + 0.01)  # Set y-axis limits with a buffer below the minimum\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InxSNyg9WRls"
      },
      "source": [
        "## **The MLP classifier with 1000 iterations had the maximum training time. The MLP classifier with 3 hidden layers follows it.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dgPQkPOWLGn"
      },
      "source": [
        "## Accuracy Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NufR44CqSu1p"
      },
      "outputs": [],
      "source": [
        "# Extract model names and accuracies for plotting\n",
        "models = list(accuracies.keys())\n",
        "accuracies = list(accuracies.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLKZDb4lQsyu"
      },
      "outputs": [],
      "source": [
        "# Get the minimum accuracy\n",
        "min_accuracy = min(accuracies)\n",
        "\n",
        "# Get the maximum accuracy\n",
        "max_accuracy = max(accuracies)\n",
        "\n",
        "# Define a color for the maximum accuracy bar\n",
        "max_accuracy_color = 'lightgreen'\n",
        "\n",
        "# Create a list to hold bar colors (default blue for all except max accuracy)\n",
        "bar_colors = ['skyblue'] * len(models)\n",
        "\n",
        "# Find the index of the model with the maximum accuracy\n",
        "max_index = accuracies.index(max_accuracy)\n",
        "\n",
        "# Set the color of the maximum accuracy bar\n",
        "bar_colors[max_index] = max_accuracy_color\n",
        "\n",
        "# Create a bar chart\n",
        "plt.figure(figsize=(8, 6))  # Adjust figure size as desired\n",
        "plt.bar(models, accuracies, color=bar_colors)\n",
        "plt.xlabel('Machine Learning Model')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Comparison of Model Accuracies')\n",
        "plt.ylim(min_accuracy - 0.01, max_accuracy + 0.01)  # Set y-axis limits with a buffer below the minimum\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0K60RHrJDxl"
      },
      "source": [
        "## **The MLP classifier is the best here with accuracy of 77.78%**\n",
        "## The data gathered is not good; the model needed a lot of training, so increasing the number of iterations to 1000 made a big increase to the accuracy as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HbE2WxJuRTX"
      },
      "source": [
        "## **To achieve a small increase in accuracy from mlp_2 to mlp_3, a big increase in training time had to be done. Data Gathering is a crucial process!**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "uS6fg3XboWP3",
        "BSudxcSHaE78",
        "A_flSC66t9Fo",
        "4pX6a7Gj5pZa",
        "gy10ZJYlE2dF",
        "TQYCnlPzF1Gs",
        "7MeEfLA0Iu6s",
        "uCYFVDeTJviL",
        "ZhbM0XJjQoEH"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}